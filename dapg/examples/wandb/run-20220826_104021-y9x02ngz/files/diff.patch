diff --git a/dapg/examples/job_script.py b/dapg/examples/job_script.py
index f8cf5ce..f361112 100644
--- a/dapg/examples/job_script.py
+++ b/dapg/examples/job_script.py
@@ -13,6 +13,7 @@ from mjrl.algos.dapg import DAPG
 from mjrl.algos.behavior_cloning import BC
 from mjrl.utils.train_agent import train_agent
 from mjrl.samplers.core import sample_paths
+from mjrl.utils.wandb import init_wandb
 import os
 import json
 import mjrl.envs
@@ -20,6 +21,7 @@ import mj_envs
 import time as timer
 import pickle
 import argparse
+import gym
 
 # ===============================================================================
 # Get command line arguments
@@ -28,7 +30,27 @@ import argparse
 parser = argparse.ArgumentParser(description='Policy gradient algorithms with demonstration data.')
 parser.add_argument('--output', type=str, required=True, help='location to store results')
 parser.add_argument('--config', type=str, required=True, help='path to config file with exp params')
+parser.add_argument('--render', type=bool, default=False, help='render the scene')
+parser.add_argument('--record_video', type=bool, default=False, help='whether recording the video')
+parser.add_argument('--record_video_interval', type=int, default=10000, help='record video interval')
+parser.add_argument('--record_video_length', type=int, default=100, help='record video length')
+parser.add_argument('--wandb_activate', type=bool, default=False, help='activate wandb for logging')
+parser.add_argument('--wandb_entity', type=str, default='', help='wandb entity')
+parser.add_argument('--wandb_project', type=str, default='', help='wandb project')
+parser.add_argument('--wandb_group', type=str, default='', help='wandb group')
+parser.add_argument('--wandb_name', type=str, default='', help='wandb name')
+
 args = parser.parse_args()
+# if not specified
+if args.record_video_interval is None:
+    args['record_video_interval'] = 100000
+if args.record_video_length is None:
+    args['record_video_length'] = 100
+print("If render, do 'export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libGLEW.so'.")
+print("If record video, undo 'export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libGLEW.so'.")
+
+print(args)
+
 JOB_DIR = args.output
 if not os.path.exists(JOB_DIR):
     os.mkdir(JOB_DIR)
@@ -42,6 +64,15 @@ EXP_FILE = JOB_DIR + '/job_config.json'
 with open(EXP_FILE, 'w') as f:
     json.dump(job_data, f, indent=4)
 
+if args.wandb_activate:
+    if len(args.wandb_project) == 0:
+        args.wandb_project = '_'.join('hand_dapg')
+    if len(args.wandb_group) == 0:
+        args.wandb_group = ''
+    if len(args.wandb_name) == 0:
+        args.wandb_name = str('_'.join([job_data['env'], job_data['algorithm']]))
+init_wandb(args)
+
 # ===============================================================================
 # Train Loop
 # ===============================================================================
@@ -99,6 +130,7 @@ print("========================================")
 ts = timer.time()
 train_agent(job_name=JOB_DIR,
             agent=rl_agent,
+            parser_args=args,
             seed=job_data['seed'],
             niter=job_data['rl_num_iter'],
             gamma=job_data['rl_gamma'],
diff --git a/dapg/examples/rl_scratch.txt b/dapg/examples/rl_scratch.txt
index 3485a82..2a3198f 100644
--- a/dapg/examples/rl_scratch.txt
+++ b/dapg/examples/rl_scratch.txt
@@ -5,7 +5,7 @@
 'env'           :   'relocate-v0',
 'algorithm'     :   'NPG',
 'seed'          :   123,
-'num_cpu'       :   5,
+'num_cpu'       :   1,
 'save_freq'     :   25,
 'eval_rollouts' :   25,
 'exp_notes'     :   'Example config for training policy with NPG from scratch on the relocate-v0 task.',
@@ -27,7 +27,7 @@
 'rl_gamma'      :   0.995,
 'rl_gae'        :   0.97,
 'rl_num_traj'   :   200,
-'rl_num_iter'   :   100,
+'rl_num_iter'   :   200,
 'lam_0'         :   0.0,
 'lam_1'         :   0.0,
 
